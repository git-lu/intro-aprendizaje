{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../images/ods_stickers.jpg\" />\n",
    "    \n",
    "# Introducción al Machine Learning 2020\n",
    "\n",
    "Basado en material de Pedro Pury y  Sebastian Raschka (sraschka@wisc.edu) Traducido y editado al español por [Ana Georgina Flesia](https://www.linkedin.com/in/georginaflesia/). Este material esta sujeto a los términos y condiciones de la licencia  [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Se permite el uso irrestricto para todo propósito no comercial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Métricas de Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Un clasificador se entrena para discriminar los ejemplos en tres\n",
    "clases (A, B y C) y en la evaluación sobre el conjunto de test\n",
    "se obtiene la siguiente matriz de confusión:\n",
    "\n",
    "        ------------------------------\n",
    "                        clasificado\n",
    "                       A    B     C    \n",
    "        ------------------------------\n",
    "                  A |  9    3     1\n",
    "    etiquetado    B |  4    8     2\n",
    "                  C |  2    1     6\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Calcular la proporción de aciertos obtenidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6388888888888888"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aciertos = 9+8+6\n",
    "total_de_predicciones = 9+4+2+3+8+1+1+2+6\n",
    "exactitud = aciertos/total_de_predicciones\n",
    "exactitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)  Calcular un intervalo de confianza del $95\\%$ para\n",
    "la métrica de exactitud. \\\\\n",
    "Justificar si es válida la aproximación normal para el cálculo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si consideramos X = la va que mide la cantidad de aciertos del clasificador, X es una variable aleatoria de Bernoulli. Las proporciones de una Bernoulli tiene distribucion binomial, que con muestras grandes (>30 podria ser) puede ser aproximada por una Gaussiana. Asi que sí, es válida una aproximacion normal.\n",
    "\n",
    "Vamos a calcular el intervalo de confianza para la proporcion de aciertos con la formula presentada en clase, de la siguiente forma:\n",
    "\n",
    "$$p = \\frac{\\hat{p} + \\frac{z^2}{2n} \\pm \\sqrt{\\hat{p}(1-\\hat{p})\\frac{z^2}{n}+\\frac{z^4}{4n}}}{1+\\frac{z^2}{n}}$$\n",
    "Para un intervalo de confianza de 95%, z=1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un intervalo de confianza del 95% para la exactitud es: (62.7364908413606,63.38077352553227)\n",
      "La longitud del intervalo de confianza es:0.6442826841716709\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "alpha = 0.05\n",
    "n = total_de_predicciones\n",
    "z = 1.96\n",
    "z_cuad = z**2\n",
    "p = exactitud\n",
    "p_superior = (p + z_cuad/2*n + sqrt(p*(1-p)*(z_cuad/n) + z_cuad**2/(4*n)))/(1+z_cuad/n) \n",
    "p_inferior = (p + z_cuad/2*n - sqrt(p*(1-p)*(z_cuad/n) + z_cuad**2/(4*n)))/(1+z_cuad/n)\n",
    "print(\"Un intervalo de confianza del 95% para la exactitud es: ({},{})\".format(p_inferior,p_superior))\n",
    "print(\"La longitud del intervalo de confianza es:{}\".format(p_superior-p_inferior))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)  Calcular el coeficiente $\\kappa$ de Cohen.\n",
    "¿Qué grado de confiabilidad tiene el clasificador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coeficiente $\\kappa$ de Cohen mide el ratio de acuerdo entre dos clasificadores presuntamente independientes. Esto nos otorga una buena medida de la reproducibilidad del clasificador, ya que la medida ademas toma en cuenta los acuerdos que se producen en forma casual.  \n",
    "¿Cómo se calcula?  \n",
    "\n",
    "$$\\kappa = \\frac{p_{o}-p_{\\epsilon}}{1-p_{\\epsilon}}$$\n",
    "\n",
    "Donde $p_{o}$ son los acuerdos observados y $p_{\\epsilon}$ la proporcion de acuerdo independiente, es decir la probabilidad hipotetica de que los clasificadores acuerden por azar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El coheficiente k es: 0.388235294117647\n"
     ]
    }
   ],
   "source": [
    "p_o = (9+8+6)/n\n",
    "# Ahora calculamos las probabilidades de acuerdo.\n",
    "# Probabilidad de que el clasificador clasifique cada valor:\n",
    "pc_A = (9+4+2)/n\n",
    "pc_B = (3+8+4)/n\n",
    "pc_C = (1+2+6)/n\n",
    "# Probabilidad de que la etiqueta sea cada valor\n",
    "pe_A = (9+3+4)/n\n",
    "pe_B = (4+8+2)/n\n",
    "pe_C = (2+1+6)/n\n",
    "# Ahora calculamos p_e, es decir, la probabilidad de que coincidan aleatoriamente\n",
    "p_e = pc_A * pe_A + pc_B * pe_B + pc_C * pe_C\n",
    "kcohen = (p_o - p_e)/(1-p_e)\n",
    "print(\"El coheficiente k es: {}\".format(kcohen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La confiabilidad en el acuerdo es baja, osea, no tenemos un clasificador muy confiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta segunda parte de esta tarea, combinará múltiples árboles de decisión dentro de un clasificadorde Bagging. Esta vez, utilizaremos el algoritmo del árbol de decisión `DecisionTreeClassifier` implementado en scikit-learn (que es una variante del algoritmo CART para divisiones binarias).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bootsrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging depende del muestreo bootstrap. Entonces, como primer paso, su tarea es implementar una función para generar muestras de arranque. En este ejercicio, por simplicidad, realizaremos los cálculos basados en el conjunto de datos de Iris.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 150\n",
      "Number of features: 4\n",
      "Unique class labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT OR DELETE THIS CELL\n",
    "import numpy as np\n",
    "from mlxtend.data import iris_data\n",
    "X, y = iris_data()\n",
    "\n",
    "print('Number of examples:', X.shape[0])\n",
    "print('Number of features:', X.shape[1])\n",
    "print('Unique class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig,ax=plt.subplots()\n",
    "ax = sns.distplot(X[:,[0]],bins=10)\n",
    "ax = sns.distplot(X[:,[1]],bins=10)\n",
    "ax = sns.distplot(X[:,[2]],bins=10)\n",
    "ax = sns.distplot(X[:,[3]],bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la función de scikit-learn `train_test_split` \n",
    "función para dividir el conjunto de datos en un conjunto de entrenamiento y prueba.\n",
    "\n",
    "\n",
    "- El conjunto de prueba debe contener 45 ejemplos, y el conjunto de entrenamiento debe contener 105 ejemplos.\n",
    "- Para garantizar resultados reproducibles, utilice '123' como semilla aleatoria.\n",
    "- Realice una división estratificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 105\n",
      "Number of test examples: 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=45,\n",
    "                                                    train_size=105,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y\n",
    "                                                   )\n",
    "\n",
    "print('Number of training examples:', X_train.shape[0])\n",
    "print('Number of test examples:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregué la siguiente celda de código para su conveniencia para verificar su solución. Si sus resultados no coinciden con los resultados que se muestran a continuación, hay un error en su implementación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 105\n",
      "Number of test examples: 45\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT OR DELETE THIS CELL\n",
    "\n",
    "print('Number of training examples:', X_train.shape[0])\n",
    "print('Number of test examples:', X_test.shape[0])\n",
    "\n",
    "\n",
    "#Number of training examples: 105\n",
    "#Number of test examples: 45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, estamos implementando una función para generar muestras bootstrap del conjunto de entrenamiento. En particular, realizaremos el bootstrapping de la siguiente manera:\n",
    "\n",
    "- Cree una matriz de índice con valores 0, ..., 104.\n",
    "- Extraiga una muestra aleatoria (con reemplazo) de esta matriz de índices utilizando el método  `choice` del objeto `RandomState` de  NumPy  que se pasa a la función como rng.\n",
    "- Seleccione ejemplos de entrenamiento de la matriz X y etiquetas del vector y utilizando la nueva muestra de índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bootstrap_sample(rng, X, y):\n",
    "    sample_indices = [ i for i in range(105)]\n",
    "    bootstrap_indices = rng.choice(sample_indices,105)\n",
    "    return X[bootstrap_indices], y[bootstrap_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Agregué la siguiente celda de código para su conveniencia para verificar su solución. Si sus resultados no coinciden con los resultados que se muestran a continuación, hay un error en su implementación de la función `draw_bootstrap_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training inputs from bootstrap round: 105\n",
      "Number of training labels from bootstrap round: 105\n",
      "Labels:\n",
      " [0 0 1 0 0 1 2 0 2 1 0 0 2 1 1 1 1 2 1 1 2 0 2 1 2 1 1 1 0 1 0 0 1 2 0 0 0\n",
      " 0 2 1 1 2 1 2 1 1 2 1 2 0 1 1 2 2 1 0 1 0 2 2 0 1 0 2 0 0 0 0 1 2 0 0 1 0\n",
      " 1 1 0 1 1 2 2 0 2 0 2 0 1 1 2 2 0 2 2 2 0 1 0 1 2 2 2 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT OR DELETE THIS CELL\n",
    "\n",
    "rng = np.random.RandomState(123)\n",
    "X_boot, y_boot = draw_bootstrap_sample(rng, X_train, y_train)\n",
    "\n",
    "print('Number of training inputs from bootstrap round:', X_boot.shape[0])\n",
    "print('Number of training labels from bootstrap round:', y_boot.shape[0])\n",
    "print('Labels:\\n', y_boot)\n",
    "\n",
    "#Number of training inputs from bootstrap round: 105\n",
    "#Number of training labels from bootstrap round: 105\n",
    "#Labels:\n",
    "# [0 0 1 0 0 1 2 0 2 1 0 0 2 1 1 1 1 2 1 1 2 0 2 1 2 1 1 1 0 1 0 0 1 2 0 0 0\n",
    "# 0 2 1 1 2 1 2 1 1 2 1 2 0 1 1 2 2 1 0 1 0 2 2 0 1 0 2 0 0 0 0 1 2 0 0 1 0\n",
    "# 1 1 0 1 1 2 2 0 2 0 2 0 1 1 2 2 0 2 2 2 0 1 0 1 2 2 2 1 0 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clasificador Baggging a partir de árboles de decisión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En esta sección, Ud implementará un algoritmo de bagging basado en `DecisionTree Classifier`. Como ayuda se proporciona una solución parcial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "class BaggingClassifier(object):\n",
    "    \n",
    "    def __init__(self, num_trees=10, random_state=123):\n",
    "        self.num_trees = num_trees\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.trees_ = [DecisionTreeClassifier(random_state=self.rng) for i in range(self.num_trees)]\n",
    "        for i in range(self.num_trees):\n",
    "            X_boot, y_boot = draw_bootstrap_sample(self.rng, X, y)\n",
    "            self.trees_[i] = self.trees_[i].fit(X_boot,y_boot)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        ary = np.zeros((X.shape[0], len(self.trees_)), dtype=np.int)\n",
    "        for i in range(len(self.trees_)):\n",
    "            ary[:, i] = self.trees_[i].predict(X)\n",
    "\n",
    "        maj = np.apply_along_axis(lambda x:\n",
    "                                  np.argmax(np.bincount(x)),\n",
    "                                            axis=1,\n",
    "                                            arr=ary)\n",
    "        return maj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregué la siguiente celda de código para su conveniencia para verificar su solución. Si sus resultados no coinciden con los resultados que se muestran a continuación, hay un error en su implementación de la función `BaggingClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Tree Accuracies:\n",
      "88.9%\n",
      "93.3%\n",
      "97.8%\n",
      "93.3%\n",
      "93.3%\n",
      "93.3%\n",
      "91.1%\n",
      "97.8%\n",
      "97.8%\n",
      "97.8%\n",
      "\n",
      "Bagging Test Accuracy: 97.8%\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT OR DELETE THIS CELL\n",
    "model = BaggingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('Individual Tree Accuracies:')\n",
    "for tree in model.trees_:\n",
    "    predictions = tree.predict(X_test) \n",
    "    print('%.1f%%' % ((predictions == y_test).sum() / X_test.shape[0] * 100))\n",
    "\n",
    "print('\\nBagging Test Accuracy: %.1f%%' % ((predictions == y_test).sum() / X_test.shape[0] * 100))\n",
    "\n",
    "#Individual Tree Accuracies:\n",
    "#88.9%\n",
    "#93.3%\n",
    "#97.8%\n",
    "#93.3%\n",
    "#93.3%\n",
    "#93.3%\n",
    "#91.1%\n",
    "#97.8%\n",
    "#97.8%\n",
    "#97.8%\n",
    "\n",
    "#Bagging Test Accuracy: 97.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Descomposición de sesgo-varianza "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este ejercicio se le pedirá que calcule los componentes de varianza y sesgo de la función de pérdida 0-1 que discutimos en clase.\n",
    "\n",
    "- En particular, calculará el sesgo promedio y la varianza promedio sobre todos los ejemplos de prueba (en lugar de un solo ejemplo de prueba).\n",
    "\n",
    "- El conjunto de datos que utilizará como conjunto de entrenamiento y conjunto de prueba es el conjunto de datos de Iris que ya dividió en `X_train` /` y_train` y `X_test` /` y_test` anteriormente.\n",
    "\n",
    "- Dado que no tenemos conjuntos de datos de entrenamiento ilimitados para estimar los parámetros, utilizaremos bootstrapping para simular \"nuevos\" conjuntos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Descomposición de sesgo-varianza  de la pérdida 0-1 para árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En esta primera parte, calculará los  sesgo y varianza promedios sobre los ejemplos del conjunto de prueba para el algoritmo del árbol de decisión implementado en scikit-learn en los datos de Iris.\n",
    "\n",
    "Ya implementé el código para calcular la \"predicción principal\" para usted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT OR DELETE THIS CELL\n",
    "\n",
    "rng = np.random.RandomState(123)\n",
    "\n",
    "num_bootstrap = 200\n",
    "# Creamos un arreglo para calcular las predicciones principales de cada\n",
    "# muestra de bootstrap\n",
    "all_pred = np.zeros((num_bootstrap, y_test.shape[0]), dtype=np.int)\n",
    "\n",
    "# Predecimos sobre el conjunto de test, para cada una de las muestras\n",
    "# de bootstraping\n",
    "tree = DecisionTreeClassifier(random_state=66)\n",
    "for i in range(num_bootstrap):\n",
    "    X_boot, y_boot = draw_bootstrap_sample(rng, X_train, y_train)\n",
    "    pred = tree.fit(X_boot, y_boot).predict(X_test)\n",
    "    all_pred[i] = pred\n",
    "    \n",
    "# Calculamos las predicciones principales como la moda de cada una de las predicciones    \n",
    "main_predictions = np.apply_along_axis(lambda x:\n",
    "                                       np.argmax(np.bincount(x)),\n",
    "                                       axis=0,\n",
    "                                       arr=all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que `all_pred` es una matriz 2D de dimensión $\\mathbb{R}^{b \\times n_{test}}$, donde $m$ es el número de iteraciones bootstrap  y $n_{test}$ es el número de ejemplos en el conjunto de prueba. En otras palabras, cada una de las 200 filas de esta matriz almacena las predicciones de una hipótesis de árbol de decisión en particular para los 45 puntos de datos de prueba.\n",
    "\n",
    "Su primera tarea es calcular el sesgo promedio sobre todos los ejemplos de prueba:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sesgo es 1 si la predicción principal no coincide con la verdadera etiqueta $y$ y 0 en otro caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 2, 2, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 2, 0, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 1, 2,\n",
       "       1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bias: 0.034555555555555555\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE\n",
    "def L(y_pred,y):\n",
    "    return y_pred != y\n",
    "\n",
    "def calculate_bias(preds,main_preds):\n",
    "    bias = 0\n",
    "    for pred,main_pred in zip(preds,main_preds):\n",
    "        bias += L(pred,main_pred)\n",
    "    return bias/len(preds)\n",
    "\n",
    "\n",
    "def avg_bias(all_pred,main_predictions):\n",
    "    biass = []\n",
    "    for i in range(len(all_pred)):\n",
    "        biass.append(calculate_bias(all_pred[i],main_predictions))\n",
    "    return np.mean(biass)\n",
    "\n",
    "bias = avg_bias(all_pred,main_predictions)\n",
    "print('Average bias:', bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su segunda tarea es calcular la varianza promedio sobre todos los ejemplos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average variance: 0.9644444444444445\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE\n",
    "# you probably need multiple\n",
    "# lines of code and a for-loop\n",
    "\n",
    "# La varianza de la peridad 0-1 se mide como la probabilidad\n",
    "# de que la etiqueta principal no coincida con la muestra.\n",
    "# Para calcularla, vamos a devolver el promedio de en cuantos\n",
    "# casos coincide y en cuantos no\n",
    "def calc_var(preds,main_preds):\n",
    "    coincidences = 0\n",
    "    for y_pred,main_pred in zip(preds,main_preds):\n",
    "        coincidences += y_pred == main_pred\n",
    "    var = coincidences/len(preds)\n",
    "    return var\n",
    "\n",
    "def avg_var(all_pred,main_predictions):\n",
    "    variances = [] \n",
    "    for i in range(len(main_predictions)):\n",
    "        variances.append(calculate_variance(all_pred[i],main_predictions))\n",
    "    return np.mean(variances)\n",
    "\n",
    "var = avg_var(all_pred,main_predictions)\n",
    "print('Average variance:', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sugerencia: Los valores promedio de sesgo y varianza son escalares, no vectores o matrices. En otras palabras, para cada una de las celdas de código anteriores, debe devolver un número real (float)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Descomposición de sesgo-varianza  de la pérdida 0-1 para Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilice el código de la sección anterior, 3.1, para comparar el algoritmo del árbol de decisión con un BaggingClassifier de scikit-learn.\n",
    "\n",
    "- Informe tanto el sesgo promedio como la varianza promedio como antes, pero use el `BaggingClassifier` en scikit-learn en lugar del` DecisionTreeClassifier`. Puede usar los valores predeterminados de `BaggingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "# YOUR SOLUTION\n",
    "# Many lines of code (which you may copy and modify from 3.1)\n",
    "all_pred = np.zeros((num_bootstrap, y_test.shape[0]), dtype=np.int)\n",
    "\n",
    "# Predecimos sobre el conjunto de test, para cada una de las muestras\n",
    "# de bootstraping\n",
    "bagging = BaggingClassifier(random_state=66)\n",
    "for i in range(num_bootstrap):\n",
    "    X_boot, y_boot = draw_bootstrap_sample(rng, X_train, y_train)\n",
    "    pred = bagging.fit(X_boot, y_boot).predict(X_test)\n",
    "    all_pred[i] = pred\n",
    "    \n",
    "# Calculamos las predicciones principales como la moda de cada una de las predicciones    \n",
    "main_predictions = np.apply_along_axis(lambda x:\n",
    "                                       np.argmax(np.bincount(x)),\n",
    "                                       axis=0,\n",
    "                                       arr=all_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bias: 0.025666666666666664\n",
      "Average variance: 0.979259259259259\n"
     ]
    }
   ],
   "source": [
    "bias = avg_bias(all_pred,main_predictions)\n",
    "var = avg_var(all_pred,main_predictions)\n",
    "print('Average bias:', bias)\n",
    "print('Average variance:', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es la varianza promedio de bagging mayor o menor que la varianza promedio del árbol de decisión en 3.1? ¿Y qué hay del sesgo promedio? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La varianza promedio y el sesgo promedio resultan muy similares porque en este dataset lo que no se pueden clasificar son unos pocos ejemplos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Descomposición de sesgo-varianza  de la pérdida 0-1 para  AdaBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Utilice el código de la sección anterior, 3.1, para comparar el algoritmo del árbol de decisión con un AdaBoostClassifier de scikit-learn.\n",
    "\n",
    "- Informe tanto el sesgo promedio como la varianza promedio como antes, pero use el `AdaboostClassifier` en scikit-learn en lugar del` DecisionTreeClassifier`. Puede usar los valores predeterminados de `AdaboostClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION\n",
    "# Many lines of code (which you may copy and modify from 3.1)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# YOUR SOLUTION\n",
    "# Many lines of code (which you may copy and modify from 3.1)\n",
    "all_pred = np.zeros((num_bootstrap, y_test.shape[0]), dtype=np.int)\n",
    "\n",
    "# Predecimos sobre el conjunto de test, para cada una de las muestras\n",
    "# de bootstraping\n",
    "for i in range(num_bootstrap):\n",
    "    X_boot, y_boot = draw_bootstrap_sample(rng, X_train, y_train)\n",
    "    pred = AdaBoostClassifier(random_state=66).fit(X_boot, y_boot).predict(X_test)\n",
    "    all_pred[i] = pred\n",
    "    \n",
    "# Calculamos las predicciones principales como la moda de cada una de las predicciones    \n",
    "main_predictions = np.apply_along_axis(lambda x:\n",
    "                                       np.argmax(np.bincount(x)),\n",
    "                                       axis=0,\n",
    "                                       arr=all_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bias: 0.032\n",
      "Average variance: 0.9758024691358023\n"
     ]
    }
   ],
   "source": [
    "bias = avg_bias(all_pred,main_predictions)\n",
    "var = avg_var(all_pred,main_predictions)\n",
    "print('Average bias:', bias)\n",
    "print('Average variance:', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es la varianza promedio de bagging mayor o menor que la varianza promedio del árbol de decisión en 3.1? ¿Y qué hay del sesgo promedio? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, es todo muy parecido porque el problema son unos poquitos ejemplos que no logra clasificar. No obtenemos una gran mejoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4)  Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este ejercicio se lepide que  que aplique un `RandomForestClassifier` en un pequeño subconjunto (10%) del conjunto de datos de dígitos manuscritos MNIST (http://yann.lecun.com/exdb/mnist/). Por conveniencia, el siguiente código carga este pequeño subconjunto a través de mlxtend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 5000 x 784\n",
      "1st row [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  51. 159. 253. 159.  50.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  48. 238. 252. 252. 252. 237.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n",
      " 227. 253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  60. 224.\n",
      " 252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252.\n",
      " 252. 253. 252. 252.  96. 189. 253. 167.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253.\n",
      " 190. 114. 253. 228.  47.  79. 255. 168.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 179.\n",
      "  12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  38. 165. 253. 233. 208.  84.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 165.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   7. 178. 252. 240.  71.  19.  28.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  57. 252. 252.  63.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 198. 253. 190.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 255. 253. 196.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  76. 246. 252. 112.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 148.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 230.  25.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   7. 135. 253. 186.  12.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 223.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   7. 131. 252. 225.  71.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 145.   0.   0.   0.   0.   0.\n",
      "   0.   0.  48. 165. 252. 173.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  86. 253. 225.   0.   0.   0.   0.   0.\n",
      "   0. 114. 238. 253. 162.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178.\n",
      " 225. 253. 223. 167.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229. 215. 252. 252.\n",
      " 252. 196. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  28. 199. 252. 252. 253. 252. 252. 233.\n",
      " 145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  25. 128. 252. 253. 252. 141.  37.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.data import mnist_data\n",
    "X, y = mnist_data()\n",
    "\n",
    "print('Dimensions: %s x %s' % (X.shape[0], X.shape[1]))\n",
    "print('1st row', X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El siguiente código muestra como se mezcla el conjunto de datos y se lo divide en 4500 ejemplos de entrenamiento y 500 ejemplos de prueba, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "\n",
    "\n",
    "X, y = shuffle_arrays_unison((X, y), random_seed=1)\n",
    "X_train, y_train = X[:4500], y[:4500]\n",
    "X_test, y_test = X[4500:], y[4500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ahora, su tarea es ajustar un clasificador RandomForest en el conjunto de entrenamiento y evaluar su precisión predictiva en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 93.60%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "acc = model.score(X_test,y_test)\n",
    "print('Accuracy {:.2f}%'.format(acc*100))\n",
    "    \n",
    "#Accuracy 93.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Luego, su tarea es cargar una imagen de un dígito (some_digit.png) de este directorio en una matriz de Python y clasificarla usando el modelo de bosque aleatorio. La imagen some_digit.png se muestra a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/some_digit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nota: Para cargar la imagen, debe instalar la biblioteca de imágenes Python PIL. En realidad, es mas recomendable instalar  Pillow. Ejecute uno de los siguientes dos si aún no ha instalado Pillow.\n",
    "    \n",
    "- `conda install Pillow`\n",
    "\n",
    "- `pip install Pillow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, preescribí parcialmente el código para usted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_image(file_name):\n",
    "    img = Image.open(file_name)\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype=np.float)\n",
    "    return data\n",
    "\n",
    "x_image = load_image('images/some_digit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 5\n"
     ]
    }
   ],
   "source": [
    "# The data needs to be represented as a vector (1 position for each feature)\n",
    "x_transf = [item for sublist in x_image for item in sublist]\n",
    "\n",
    "# Also, scikit-learn expects 2D arrays, so we need to add a dimension\n",
    "x_transf = np.expand_dims(x_transf,axis=0)\n",
    "\n",
    "print('Digit:', model.predict(x_transf)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
